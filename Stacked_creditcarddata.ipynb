{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtlD+jaRHwgyRlff3UPIMv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chirag314/Stacked-creditcarddata/blob/main/Stacked_creditcarddata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###This notebook is made from exercises from book Ensemble Machine Learning Cookbook."
      ],
      "metadata": {
        "id": "de3ggC8Kv_99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacked generalization is an ensemble of a diverse group of models that introduces the concept of a meta-learner. A meta-learner is a second-level machine learning algorithm that learns from an optimal combination of base learners:\n",
        "The steps for stacking are as follows:\n",
        "\n",
        "Split your dataset into a training set and a testing set.\n",
        "Train several base learners on the training set.\n",
        "Apply the base learners on the testing set to make predictions.\n",
        "Use the predictions as inputs and the actual responses as outputs to train a higher-level learner.\n",
        "Stacked generalization is used mainly for minimizing the generalization error of the base learners, and can be seen as a refined version of cross-validation. It uses a strategy that's more sophisticated than cross-validation's winner-takes-all approach for combining the predictions from the base learners.\n",
        "In this section, we'll look at how to implement stacked generalization from scratch.\n",
        "\n",
        "We will carry out the following steps to get started:\n",
        "\n",
        "Build three base learners for stacking.\n",
        "Combine the predictions from each of the base learners.\n",
        "Build the meta-learner using another algorithm."
      ],
      "metadata": {
        "id": "jIDLriSFoPIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_tree\n",
        "from xgboost import plot_importance\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score,r2_score,roc_curve, auc,accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import itertools\n",
        "\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "CWjW7ISB-O8s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rror9ooAv2jU",
        "outputId": "7487c090-fc88-4f65-c658-b50d26f3f9e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
            "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
            "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
            "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
            "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
            "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
            "\n",
            "   PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
            "0     -2     -2     3913.0     3102.0      689.0        0.0        0.0   \n",
            "1      0      2     2682.0     1725.0     2682.0     3272.0     3455.0   \n",
            "2      0      0    29239.0    14027.0    13559.0    14331.0    14948.0   \n",
            "3      0      0    46990.0    48233.0    49291.0    28314.0    28959.0   \n",
            "4      0      0     8617.0     5670.0    35835.0    20940.0    19146.0   \n",
            "\n",
            "   BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
            "0        0.0       0.0     689.0       0.0       0.0       0.0       0.0   \n",
            "1     3261.0       0.0    1000.0    1000.0    1000.0       0.0    2000.0   \n",
            "2    15549.0    1518.0    1500.0    1000.0    1000.0    1000.0    5000.0   \n",
            "3    29547.0    2000.0    2019.0    1200.0    1100.0    1069.0    1000.0   \n",
            "4    19131.0    2000.0   36681.0   10000.0    9000.0     689.0     679.0   \n",
            "\n",
            "   default.payment.next.month  \n",
            "0                           1  \n",
            "1                           1  \n",
            "2                           0  \n",
            "3                           0  \n",
            "4                           0  \n"
          ]
        }
      ],
      "source": [
        "# Read data from github. Use raw format and copy url# Note normal url and raw url will be different.\n",
        "import pandas as pd\n",
        "pd.options.display.max_rows=None\n",
        "pd.options.display.max_columns=None\n",
        "url = 'https://raw.githubusercontent.com/PacktPublishing/Ensemble-Machine-Learning-Cookbook/master/Chapter08/UCI_Credit_Card.csv'\n",
        "df_creditcarddata= pd.read_csv(url)\n",
        "#df = pd.read_csv(url)\n",
        "print(df_creditcarddata.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check shape of data\n",
        "df_creditcarddata.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9gCg8741boR",
        "outputId": "afd45a93-d148-4968-978b-5877b9a88540"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature and response variables\n",
        "X=df_creditcarddata.iloc[:,0:23]\n",
        "\n",
        "Y=df_creditcarddata['default.payment.next.month']\n",
        "print(X.shape)\n",
        "print(Y.shape)\n"
      ],
      "metadata": {
        "id": "1YxyHEe749sY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81c2fe6-9bd8-4075-a7b4-d780ad7bdb1f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 23)\n",
            "(30000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check missing values\n",
        "df_creditcarddata.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KEEbG5K12Ac",
        "outputId": "9aa30882-d6fa-4f83-cde3-ca72a4e2e96b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                            0\n",
              "LIMIT_BAL                     0\n",
              "SEX                           0\n",
              "EDUCATION                     0\n",
              "MARRIAGE                      0\n",
              "AGE                           0\n",
              "PAY_0                         0\n",
              "PAY_2                         0\n",
              "PAY_3                         0\n",
              "PAY_4                         0\n",
              "PAY_5                         0\n",
              "PAY_6                         0\n",
              "BILL_AMT1                     0\n",
              "BILL_AMT2                     0\n",
              "BILL_AMT3                     0\n",
              "BILL_AMT4                     0\n",
              "BILL_AMT5                     0\n",
              "BILL_AMT6                     0\n",
              "PAY_AMT1                      0\n",
              "PAY_AMT2                      0\n",
              "PAY_AMT3                      0\n",
              "PAY_AMT4                      0\n",
              "PAY_AMT5                      0\n",
              "PAY_AMT6                      0\n",
              "default.payment.next.month    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We first split the dataset into train and test subset\n",
        "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.1,random_state=1)\n",
        "\n",
        "#Then we take the train subset and carve out as validation set\n",
        "X_train, X_val, Y_train,Y_val=train_test_split(X_train,Y_train,test_size=0.2,random_state=1)"
      ],
      "metadata": {
        "id": "mO3iJsxv19TW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check dimension of each subset to make sure the split is proper\n",
        "#Dimension of train subsets\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "#Dimensions of validation subsets\n",
        "print(X_val.shape)\n",
        "print(Y_val.shape)\n",
        "\n",
        "# Check dimensions of test set\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMqEDEhSeB1Z",
        "outputId": "1f79e4c6-2b44-4303-f735-d3f6d70eca23"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21600, 23)\n",
            "(21600,)\n",
            "(5400, 23)\n",
            "(5400,)\n",
            "(3000, 23)\n",
            "(3000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import required libraries\n",
        "#For base learners\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# For metalearner\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "WVLdchQ2egIz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create instances of base learners and fit the model on our training dataa\n",
        "#The base learners\n",
        "model_1=GaussianNB()\n",
        "model_2=KNeighborsClassifier(n_neighbors=1)\n",
        "model_3=DecisionTreeClassifier()\n",
        "\n",
        "#Now we train a list of models\n",
        "base_learner_1=model_1.fit(X_train,Y_train)\n",
        "base_learner_2=model_2.fit(X_train,Y_train)\n",
        "base_learner_3=model_3.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "ILXkGCXveyro"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We then use the models to make predictions\n",
        "val_prediction_base_learner_1=base_learner_1.predict(X_val)\n",
        "val_prediction_base_learner_2=base_learner_2.predict(X_val)\n",
        "val_prediction_base_learner_3=base_learner_3.predict(X_val)"
      ],
      "metadata": {
        "id": "DFGXHqf_gHxs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And then use the predictions to create a new stacked dataset\n",
        "import numpy as np\n",
        "prediction_test_stack=np.dstack([val_prediction_base_learner_1, val_prediction_base_learner_2,val_prediction_base_learner_3])\n",
        "\n",
        "#Now we stack actual outcomes\n",
        "final_train_stack=np.dstack([prediction_test_stack,Y_val])"
      ],
      "metadata": {
        "id": "7ePHiVfUghax"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We convert the final_train_stack stacked array to a DataFrame and add column names to each of the columns. Verify the dimensions and take a look at the first few rows:"
      ],
      "metadata": {
        "id": "ojzXRBf5hC90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_train_dataframe=pd.DataFrame(final_train_stack[0,0:5400],columns='NB_val KNN_val DT_val Y_val'.split())\n",
        "\n",
        "print(stacked_train_dataframe.shape)\n",
        "print(stacked_train_dataframe.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xw0w1yYhCLZ",
        "outputId": "a4ba5d1d-3fd5-4154-9068-eac3223a2c37"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5400, 4)\n",
            "   NB_val  KNN_val  DT_val  Y_val\n",
            "0       1        0       0      0\n",
            "1       1        1       0      1\n",
            "2       1        0       0      0\n",
            "3       1        0       1      1\n",
            "4       1        0       0      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the meta-learner using the stacked array\n",
        "meta_learner=LogisticRegression()\n",
        "meta_learner_model=meta_learner.fit(stacked_train_dataframe.iloc[:,0:3],stacked_train_dataframe['Y_val'])"
      ],
      "metadata": {
        "id": "fSB_yMyMhec5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the test data (new data)\n",
        "# Apply the base learners on this new data to make predictions\n",
        "# We now use the models to make predictions on the test data and create a new stacked dataset\n",
        "\n",
        "test_prediction_base_learner_1=base_learner_1.predict(X_test)\n",
        "test_prediction_base_learner_2=base_learner_2.predict(X_test)\n",
        "test_prediction_base_learner_3=base_learner_3.predict(X_test)\n",
        "\n",
        "# Create the stacked data\n",
        "final_test_stack=np.dstack([test_prediction_base_learner_1,test_prediction_base_learner_2,test_prediction_base_learner_3])"
      ],
      "metadata": {
        "id": "uny_7PBmh4vw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the final_test_stack stacked array to a DataFrame and add column names to each of the columns. Verify the dimensions and take a look at the first few rows:"
      ],
      "metadata": {
        "id": "B29zAeNtiX2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_test_dataframe=pd.DataFrame(final_test_stack[0,0:3000],columns='NB_TEST KNN_TEST DT_TEST'.split())\n",
        "print(stacked_test_dataframe.shape)\n",
        "print(stacked_test_dataframe.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebtXqQxpiY-K",
        "outputId": "74fb6d37-450f-43e9-9d7f-a696d81627e7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3000, 3)\n",
            "   NB_TEST  KNN_TEST  DT_TEST\n",
            "0        1         0        0\n",
            "1        1         1        0\n",
            "2        0         0        0\n",
            "3        1         0        1\n",
            "4        1         0        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the accuracy of base learner on our original test data\n",
        "test_prediction_base_learner_1=base_learner_1.predict(X_test)\n",
        "test_prediction_base_learner_2=base_learner_2.predict(X_test)\n",
        "test_prediction_base_learner_3=base_learner_3.predict(X_test)\n",
        "\n",
        "print(\"Accuracy from GaussianNB :\",accuracy_score(Y_test,test_prediction_base_learner_1))\n",
        "print(\"Accuracy from KNN :\", accuracy_score(Y_test, test_prediction_base_learner_2))\n",
        "print(\"Accuracy from Decision tree: \",accuracy_score(Y_test, test_prediction_base_learner_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln2kEJ8yi24w",
        "outputId": "213246fb-59bb-437c-8b59-329594993632"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy from GaussianNB : 0.398\n",
            "Accuracy from KNN : 0.696\n",
            "Accuracy from Decision tree:  0.7433333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the meta-learner on the stacked test data and check the accuracy\n",
        "test_predictions_meta_learner=meta_learner_model.predict(stacked_test_dataframe)\n",
        "print(\"Accuracy from meta learner:\", accuracy_score(Y_test, test_predictions_meta_learner))\n",
        "#We see the following output returned by the meta-learner applied on the stacked test data. This accuracy is higher than the individual base learners"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRQbBJbujiqM",
        "outputId": "dc1d2b4c-53d0-4403-95fe-9ad4dc7679e6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy from meta learner: 0.7746666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
            "Feature names unseen at fit time:\n",
            "- DT_TEST\n",
            "- KNN_TEST\n",
            "- NB_TEST\n",
            "Feature names seen at fit time, yet now missing:\n",
            "- DT_val\n",
            "- KNN_val\n",
            "- NB_val\n",
            "\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    }
  ]
}